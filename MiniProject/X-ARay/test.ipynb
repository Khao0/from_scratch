{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLAHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLAHE = cv2.createCLAHE(clipLimit=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xray = cv2.imread(\"Input/x-ray.png\", cv2.IMREAD_UNCHANGED) \n",
    "# xray_gray = cv2.cvtColor(xray, cv2.COLOR_RGBA2GRAY)\n",
    "clahe_image = CLAHE.apply(xray)\n",
    "xray_rgb = cv2.cvtColor(clahe_image, cv2.COLOR_GRAY2RGB)\n",
    "cv2.imwrite(\"x-ray_clahe.png\", xray_rgb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand X-ray Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 960x768 1 class_0, 711.5ms\n",
      "Speed: 3.0ms preprocess, 711.5ms inference, 0.3ms postprocess per image at shape (1, 3, 960, 768)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def detect(img, model):\n",
    "    pred = model(img)\n",
    "    try:\n",
    "        pred = pred[0].boxes.xyxy[0].tolist()\n",
    "        bbox = [int(i) for i in pred]\n",
    "        cropped_image = img[bbox[1] : bbox[3], bbox[0] : bbox[2]]\n",
    "    except:\n",
    "        cropped_image = img\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "detection_model = YOLO(f\"models/detection.pt\")\n",
    "cropped_xray = detect(xray_rgb, detection_model)\n",
    "cv2.imwrite(\"cropped_xray.png\", cropped_xray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentatin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 960x672 1 class_0, 723.5ms\n",
      "Speed: 3.0ms preprocess, 723.5ms inference, 0.9ms postprocess per image at shape (1, 3, 960, 672)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_mask(img: np.ndarray, model) -> np.ndarray:\n",
    "    H, W, _ = img.shape\n",
    "    results = model(img)\n",
    "    if results[0].masks is None:\n",
    "        masked_img = img\n",
    "    else:\n",
    "        for result in results:\n",
    "            for j, mask_pred in enumerate(result.masks.data):\n",
    "                mask_pred = (mask_pred.cpu().numpy() * 255).astype(np.uint8)\n",
    "                mask_pred = cv2.resize(mask_pred, (W, H))\n",
    "\n",
    "        mask_pred = cv2.cvtColor(mask_pred, cv2.COLOR_GRAY2BGR)\n",
    "        masked_img = cv2.bitwise_and(img, mask_pred)\n",
    "    return masked_img\n",
    "segmentation_model = YOLO(f\"models/segmentation.pt\")\n",
    "\n",
    "masked_img = create_mask(cropped_xray, segmentation_model)\n",
    "cv2.imwrite(\"masked_xray.png\", masked_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webcam and Mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_fist(hand_landmarks):\n",
    "    fingers = []\n",
    "    for i in [8, 12, 16, 20]:  # Index, Middle, Ring, Pinky tips\n",
    "        if hand_landmarks.landmark[i].y < hand_landmarks.landmark[i - 2].y:\n",
    "            fingers.append(1)  # Extended\n",
    "        else:\n",
    "            fingers.append(0)  # Folded\n",
    "    return sum(fingers) == 0  # If all fingers are folded, it's a fist\n",
    "\n",
    "def extract_name(bn:str)->str:\n",
    "    if bn == \"Wrist\":\n",
    "        return \"Wrist\"\n",
    "    elif bn == \"\":\n",
    "        return \"\"\n",
    "    else:\n",
    "        return figure_name[bn[0]] + \" \" + bone_name[bn[1:3]]\n",
    "\n",
    "# Initialize MediaPipe Hands for detection (without tracking)\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "# which detect only one hand and set confidence to 0.5\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5\n",
    ")\n",
    "\n",
    "# X-ray starts ON\n",
    "opacity = 0.6  # Initial opacity of the X-ray image\n",
    "torelance_x = 40 # pixel\n",
    "torelance_y = 60\n",
    "bone_name = {\"DP\": \"Distal Phalanx\", \"MP\": \"Middle Phalanx\", \"PP\": \"Proximal Phalanx\", \"ME\": \"Metacarpal\"}\n",
    "figure_name = {\"T\": \"Thumb\", \"I\": \"Index\", \"M\": \"Middle\", \"R\": \"Ring\", \"P\": \"Pinky\"}\n",
    "\n",
    "# Bone name\n",
    "bone = {0: [\"Wrist\",0,0], 1:[\"\",0,0],2:[\"TME\",0,0], 3:[\"TPP\",0,0], 4:[\"TDP\",0,0], 5:[\"IME\",0,0], 6:[\"IPP\",0,0], 7:[\"IMP\",0,0],8:[\"IDP\",0,0],9:[\"MME\", 0,0],10:[\"MPP\",0,0],11:[\"MMP\",0,0],12:[\"MDP\",0,0],13:[\"RME\",0,0],14:[\"RPP\",0,0],15:[\"RMP\",0,0],16:[\"RDP\",0,0],17:[\"PME\",0,0],18:[\"PPP\",0,0],19:[\"PMP\",0,0],20:[\"PDP\",0,0]}\n",
    "webcam = cv2.VideoCapture(0)\n",
    "\n",
    "while webcam.isOpened():\n",
    "    success, frame = webcam.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # Flip the frame horizontally for a mirror effect\"\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w, _ = frame.shape\n",
    "\n",
    "    # Convert BGR to RGB for MediaPipe processing\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process hand detection\n",
    "    result = hands.process(rgb_frame)\n",
    "    xray_enabled = True\n",
    "    left_hand = None\n",
    "    right_hand = None\n",
    "\n",
    "    if result.multi_hand_landmarks:\n",
    "        for i, hand_landmarks in enumerate(result.multi_hand_landmarks):\n",
    "            hand_label = result.multi_handedness[i].classification[0].label\n",
    "            if hand_label == \"Left\":\n",
    "                left_hand = hand_landmarks\n",
    "            elif hand_label == \"Right\":\n",
    "                right_hand = hand_landmarks\n",
    "        \n",
    "        # Get bounding box around the hand\n",
    "        if right_hand and is_fist(right_hand):\n",
    "            xray_enabled = False\n",
    "        else:\n",
    "            xray_enabled = True\n",
    "\n",
    "        if xray_enabled and right_hand is not None: \n",
    "\n",
    "            # === 1. Overlay X-ray Image Using Right Hand ===\n",
    "            # right_hand_landmarks = hand_positions[\"Right\"]\n",
    "\n",
    "            x_min, y_min = w, h\n",
    "            x_max, y_max = 0, 0\n",
    "\n",
    "            # Get bounding box of the right hand\n",
    "            for i, landmark in enumerate(right_hand.landmark):\n",
    "                x, y = int(landmark.x * w), int(landmark.y * h)\n",
    "                x_min, y_min = min(x_min, x), min(y_min, y)\n",
    "                x_max, y_max = max(x_max, x), max(y_max, y)\n",
    "\n",
    "                # # Draw a circle on the index fingertip\n",
    "                # cv2.circle(frame, (x, y), 10, (0, 255, 0), -1)\n",
    "\n",
    "                # # Optional: Draw landmarks and connections\n",
    "                # mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                bone[i][1] =x\n",
    "                bone[i][2] =y\n",
    "\n",
    "            # Expand the bounding box slightly\n",
    "            padding = 50\n",
    "            x_min, y_min = max(0, x_min - padding), max(0, y_min - padding)\n",
    "            x_max, y_max = min(w, x_max + padding), min(h, y_max + padding)\n",
    "            # cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), thickness=4)\n",
    "\n",
    "            hand_width = x_max - x_min\n",
    "            hand_height = y_max - y_min\n",
    "            \n",
    "            xray_resized = cv2.resize(masked_img, (hand_width, hand_height))\n",
    "            \n",
    "            # Extract Region of Interest from the frame which is the real hand and overlay by the x-ray image\n",
    "            roi = frame[y_min:y_max, x_min:x_max]\n",
    "\n",
    "            #create 2D alpha mask\n",
    "            alpha = np.ones((xray_resized.shape[0], xray_resized.shape[1]), dtype=np.float32) * opacity  # Default alpha\n",
    "            # Convert alpha to 3-channel for blending\n",
    "            alpha = np.expand_dims(alpha, axis=-1)  # Shape (h, w, 1)\n",
    "            # Blend the images using alpha transparency\n",
    "            roi = ((1 - alpha) * roi.astype(np.float32) + alpha * xray_resized.astype(np.float32)).astype(np.uint8)\n",
    "\n",
    "            # Replace the overlay region into the frame\n",
    "            frame[y_min:y_max, x_min:x_max] = roi\n",
    "\n",
    "            # === 2. Adjust Opacity Using Left Hand ===\n",
    "            if left_hand:\n",
    "                # The screen start top-left corner is (0, 0)\n",
    "                # The hand landmarks are normalized to the range [0, 1]\n",
    "                # So, the higher the y value mean low position of the hand\n",
    "                index_finger_tip_y = left_hand.landmark[8].y\n",
    "                index_finger_pip_y= left_hand.landmark[6].y\n",
    "                middle_finger_tip_y = left_hand.landmark[12].y\n",
    "                middle_finger_pip_y = left_hand.landmark[10].y\n",
    "                ring_finger_tip_y = left_hand.landmark[16].y\n",
    "                ring_finger_pip_y = left_hand.landmark[14].y\n",
    "                pinky_finger_tip_y = left_hand.landmark[20].y\n",
    "                pinky_finger_pip_y = left_hand.landmark[18].y\n",
    "\n",
    "                #3 fingure to increase opacity\n",
    "                if index_finger_tip_y < index_finger_pip_y and \\\n",
    "                    middle_finger_tip_y < middle_finger_pip_y and \\\n",
    "                    ring_finger_tip_y < ring_finger_pip_y and \\\n",
    "                    pinky_finger_tip_y > pinky_finger_pip_y:\n",
    "                    opacity = min(1.0, opacity + 0.005)\n",
    "                # 2 fingure to decrease opacity\n",
    "                elif index_finger_tip_y < index_finger_pip_y and \\\n",
    "                    middle_finger_tip_y < middle_finger_pip_y and \\\n",
    "                    ring_finger_tip_y > ring_finger_pip_y and \\\n",
    "                    pinky_finger_tip_y > pinky_finger_pip_y:\n",
    "                    opacity = max(0.0, opacity - 0.005)\n",
    "                # 1 figure to show tip for each bone\n",
    "                elif index_finger_tip_y < index_finger_pip_y and \\\n",
    "                    middle_finger_tip_y > middle_finger_pip_y and \\\n",
    "                    ring_finger_tip_y > ring_finger_pip_y and \\\n",
    "                    pinky_finger_tip_y > pinky_finger_pip_y: # condition\n",
    "                    index_finger_tip_x = left_hand.landmark[8].x*w\n",
    "                    index_finger_tip_y = left_hand.landmark[8].y*h\n",
    "                    for i in range(0, 21):\n",
    "                        if abs(bone[i][1]-torelance_x) < index_finger_tip_x < abs(bone[i][1]+torelance_x) and abs(bone[i][2]-torelance_y) < index_finger_tip_y < abs(bone[i][2]+torelance_y):\n",
    "                            name = extract_name(bone[i][0]) \n",
    "                            cv2.putText(frame, name, (int(index_finger_tip_x), int(index_finger_tip_y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 4)\n",
    "                            break\n",
    "\n",
    "    \n",
    "\n",
    "    cv2.imshow(\"AR Hand X-ray\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF  # Get the key input\n",
    "\n",
    "    if key == ord(\"q\"):  # Press 'q' to quit\n",
    "        break\n",
    "    elif key == ord(\"c\"):\n",
    "        timestamp = time.strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "        cv2.imwrite(f\"Outputs/Overlay_{timestamp}.png\", roi)\n",
    "\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
